{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vRNsV_iVtPS"
   },
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neM1hHdQVtPX"
   },
   "source": [
    "# 5.0 컴퓨터 비전을 위한 다중 노드 분산 학습\n",
    "\n",
    "이번 실습에서는 분산 모드에서 간단한 이미지 분류기를 학습하는 방법에 대해 알아보겠습니다.\n",
    "우리는 먼저 바닐라 파이프라인 병렬 분산을 구현할 것입니다. 그런 다음 모델 배포 및 최적화 기술을 위해 마이크로소프트의 [DeepSpeed Library](https://www.deepspeed.ai/)를 사용합니다.\n",
    "\n",
    "## 목표\n",
    "\n",
    "이번 노트북의 목표는 다음과 같습니다 :\n",
    "* 바닐라 CNN을 트레이닝하는 방법\n",
    "* DeepSpeed 라이브러리 코드 포팅하기 \n",
    "* 데이터 병렬화 분산을 활용하여 트레이닝 스케일링하기\n",
    "* DeepSpeed 오토 튜닝 및 ZeRO(Zero Redundancy Optimizer) 도구를 사용하여 학습 최적화\n",
    "\n",
    "\n",
    "**[5.1 CIFAR-10에서 이미지 분류를 위한 합성곱 신경망](#1.1-The-hardware-overview)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.1.1 데이터세트](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.1.2 합성곱 신경망](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.1.3 단순한 모델 분산](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "**[5.2 DeepSpeed로 분산 학습](#1.1-The-hardware-overview)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.1 DeepSpeed로 코드 실행하기](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.2 데이터 병렬화로 트레이닝 스케일링 하기](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.3 ZeRO (Zero Redundancy Optimizer) ](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "\n",
    "### 기존 실행 중이거나 보류 상태의 Job을 취소니다. \n",
    "\n",
    "실습 진행에 앞서  SLURM 대기열에서 아직 실행 중이거나 대기 중인 작업이 없는지 확인하십시오. 다음 셀을 실행하여 SLURM 작업 대기열을 확인합니다. :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_Qd40d-VtPY"
   },
   "outputs": [],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJHbbFAHVtPa"
   },
   "source": [
    "아직 실행 중이거나 보류 중인 작업이 있는 경우 다음 셀을 실행하고 `scancel` 명령을 사용하여 모든 사용자의 작업을 취소합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ_06fBlVtPa"
   },
   "outputs": [],
   "source": [
    "# Cancel admin user jobs\n",
    "! scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "! squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-VVA7MQVtPb"
   },
   "source": [
    "---\n",
    "# 5.1 CIFAR-10에서 이미지 분류를 위한 합성곱 신경망\n",
    "\n",
    "## 5.1.1 데이터세트\n",
    "\n",
    "\n",
    "[CIFAR-10 데이터세트](https://www.cs.toronto.edu/~kriz/cifar.html)는 6만개의 이미지(훈련용 5만, 테스트용 1만)로 구성됩니다. 데이터세트는 비행기, 자동차, 새, 고양이, 사슴, 개, 개구리, 말, 배, 트럭 등 10가지 클래스로 분류된 32x32 픽셀 이미지입니다.\n",
    "이번 실습에서, 우리는 CIFAR-10 이미지를 분류하기 위한 간단한 합성곱 신경망을 훈련시킬 것입니다.\n",
    "\n",
    "데이터세트를 다운로드하기 위해 Computer Vision을 위한 인기 데이터 세트, 모델 아키텍처 및 공통 이미지 변환을 포함하는 Pytorch 라이브러리인  [Torchvision](https://pytorch.org/vision/stable/index.html)  패키지를 사용합니다.\n",
    "<img src=\"images/CIFAR-10.jpg\" width=\"350\" />\n",
    "\n",
    "먼저 다음 셀을 실행하여 관련 라이브러리를 가져오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDEsGFqBVtPb"
   },
   "outputs": [],
   "source": [
    "# import the relevant libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import display_html\n",
    "\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "\n",
    "# define an image tranform \n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiLDX5v_VtPc"
   },
   "source": [
    "다음 2개의 셀을 실행하여 훈련 및 테스트용 CIFAR10 코퍼스를 다운로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-vPLkryVtPd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download the CIFAR10 training dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQge3pe0VtPd"
   },
   "outputs": [],
   "source": [
    "# Download the CIFAR10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=64,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnLEoYRoVtPe"
   },
   "source": [
    "데이터세트의 몇 가지 예시를 살펴보겠습니다.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZl7l3PbVtPe"
   },
   "outputs": [],
   "source": [
    "# Show some random training images\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(images, labels):\n",
    "    for i in range(8): \n",
    "        img = images[i] / 2 + 0.5\n",
    "        npimg = img.numpy()\n",
    "        plt.subplot(2,4,i+1)\n",
    "        plt.imshow(np.transpose(npimg, (1, 2 , 0)));\n",
    "        plt.axis('off');\n",
    "        plt.title(classes[labels[i]])\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# get some training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "# Show images\n",
    "imshow(images,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLDKUuqnVtPf"
   },
   "source": [
    "## 5.1.2 합성곱 신경망\n",
    "\n",
    "2개의 컨볼루션 레이어로 신경망을 정의합니다. 먼저 풀링 레이어를 정의한 후 3개의 완전히 연결된 레이어를 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9AUcANrVtPf"
   },
   "outputs": [],
   "source": [
    "# Define the CNN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "cnn_net = CNN_Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGgXWbn3VtPf"
   },
   "outputs": [],
   "source": [
    "# Copy the model to GPU 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYwTzSbLVtPg"
   },
   "outputs": [],
   "source": [
    "# Let's have a look at the Convolutional Neural Network\n",
    "from torchsummary import summary\n",
    "summary(cnn_net,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA8u_JttVtPg"
   },
   "source": [
    "옵티마이저와 하이퍼 파라미터를 정의합니다. 우리는 모멘텀 옵티마이저와 함께 확률적 경사 하강법(SGD)을 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tACyMEdVtPg"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_net.parameters(), lr=0.001,momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# Tensorboard event recording directory \n",
    "writer = SummaryWriter('megatron/tensorboard/cifar10')\n",
    "\n",
    "log_interval=100\n",
    "batch_size=64\n",
    "epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOFaRMRhVtPh"
   },
   "outputs": [],
   "source": [
    "# Train the CNN\n",
    "for epoch in range(epochs): \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = cnn_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()     \n",
    "        \n",
    "        # print the loss and accuracy metrics very log_interval mini-batches\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        if i % log_interval == (log_interval - 1):  \n",
    "            print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / log_interval, 100.*correct/total))\n",
    "            writer.add_scalar(\"Training Cross Entropy Loss\", running_loss / log_interval, i + 1)\n",
    "            writer.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "            running_loss = 0.0\n",
    "    # print the last iterations \n",
    "    print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / ((i % log_interval) + 1), 100.*correct/total))\n",
    "    writer.add_scalar(\"Training Cross Entropy Loss\", running_loss / ((i % log_interval) + 1), i + 1)\n",
    "    writer.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "\n",
    "print('Training Done')\n",
    "writer.add_graph(cnn_net, inputs)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMQgS4IjVtPh"
   },
   "source": [
    "### Tensorboard에서 학습 과정을 모니터링하고 모델을 검사합니다. \n",
    "\n",
    "우리는 이전 CNN 트레이닝 시, Tensorboard 이벤트를 기록하기 위한 인수 값을 설정합니다. 훈련 로스는 `cifar10`이라는 이름으로 확인 가능합니다. 또한 모델을 시각화하고 \"Graphs\" 탭에서 해당 레이어 전체를 탐색할 수 있습니다.\n",
    "\n",
    "<img src=\"images/CNN.png\" width=\"750\"/>\n",
    "\n",
    "다음 셀을 실행하여 브라우저용 Tensorboard 링크를 만듭니다. 그런 다음 링크를 클릭하면 지정된 `Tensorboard` 디렉토리에 저장된 실험 수치 그래프들을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-9LBAjJVtPh"
   },
   "outputs": [],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/tensorboard/';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Tensorboard!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evG_DE8BVtPi"
   },
   "source": [
    "### 훈련된 모델을 평가합니다.\n",
    "\n",
    "CIFAR-10 테스트 데이터 세트에서 훈련된 모델을 평가해 보겠습니다. 다음 셀을 실행하여 테스트 데이터 세트의 정확도를 평가합니다. 클래스별 정확도 세부 정보도 표시됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "error",
     "timestamp": 1661305130987,
     "user": {
      "displayName": "Solee Moon KR",
      "userId": "15448835692925759007"
     },
     "user_tz": -540
    },
    "id": "q7szHrwvVtPi",
    "outputId": "89942a93-f243-409f-c92f-5af38d362292"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d086ba93663e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = cnn_net(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        c = (predicted == labels.to(device)).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %2f %%' %\n",
    "      (100 * correct / total))\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2f %%' %\n",
    "          (classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_ZNKIBKVtPi"
   },
   "source": [
    "# 5.1.3 단순 모델 분산\n",
    "\n",
    "이제 이전의 CNN 모델을 활용하여 단순 파이프라인 병렬 분포를 구현해 보겠습니다. 그러기 위해서는, 각 레이어를 디바이스에 명시적으로 배치하고 순방향 패스를 구현하여 해당 출력을 디바이스와 일치시켜야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaIzfhzOVtPi"
   },
   "source": [
    "우리는 두 개의 GPU에서 CNN 모델을 실행합니다. 이때, GPU0에 conv1 + pooling을 배치하고 GPU1에 conv2 + fc1 + fc2 + fc3를 배치하겠습니다.\n",
    "우리는 텐서를 cuda로 변환하여 원하는 장치에 배치하기 위해 토치 *[TORCH.TENSOR.TO](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to)* 를 사용합니다. \n",
    "\n",
    "정의된 `Net_Parallel`클래스에서 수정된 클래스를 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73fN5YecVtPj"
   },
   "outputs": [],
   "source": [
    "# Define the CNN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net_Parallel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_Parallel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5).to('cuda:0')               # Changed here\n",
    "        self.pool = nn.MaxPool2d(2, 2).to('cuda:0')                # Changed here\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5).to('cuda:1')              # Changed here\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120).to('cuda:1')         # Changed here\n",
    "        self.fc2 = nn.Linear(120, 84).to('cuda:1')                 # Changed here\n",
    "        self.fc3 = nn.Linear(84, 10).to('cuda:1')                  # Changed here\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x.to('cuda:0'))))          # Changed here\n",
    "        x = self.pool(F.relu(self.conv2(x.to('cuda:1'))))          # Changed here\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "cnn_net_pp = Net_Parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9RZv34VVtPj"
   },
   "source": [
    "이전 훈련 실행과 마찬가지로 다음 2개의 셀을 실행하여 옵티마이저/하이퍼 매개 변수를 정의한 다음 훈련을 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Itramd41VtPj"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_net_pp.parameters(), lr=0.001,momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# Tensorboard event recording directory \n",
    "writer_pp = SummaryWriter('megatron/tensorboard/cifar10_PP')                 \n",
    "\n",
    "log_interval=100\n",
    "batch_size=64\n",
    "epochs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfmdku21VtPj"
   },
   "source": [
    "다음 셀을 실행하여 터미널을 열고 watch `nvidia-smi` 명령어를 실행하면 GPU 활동을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZkP4uLvVtPj"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<pre>\n",
    "   Step 1: Open a terminal session by following the <a href=\"\", data-commandlinker-command=\"terminal:create-new\">Terminal link</a>\n",
    "   Step 2: Check the GPUs: <font color=\"green\">watch nvidia-smi</font>\n",
    "</pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bINLTG4-VtPk"
   },
   "source": [
    "터미널 창을 열어두고 다음 학습을 실행하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ok_4pIQVtPk"
   },
   "outputs": [],
   "source": [
    "# Train the CNN with pipeline parallel\n",
    "for epoch in range(epochs): \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = cnn_net_pp(inputs.to('cuda:0'))                                # Changed here\n",
    "        loss = criterion(outputs, labels.to('cuda:1'))                           # Changed here\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.reset_max_memory_allocated(0)\n",
    "        # print the loss and accuracy metrics very log_interval mini-batches\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.to('cuda:1')).sum().item()                 # Changed here\n",
    "        if i % log_interval == (log_interval - 1):  \n",
    "            print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / log_interval, 100.*correct/total))\n",
    "            writer_pp.add_scalar(\"Training Cross Entropy Loss\", running_loss / log_interval, i + 1)\n",
    "            writer_pp.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "            running_loss = 0.0\n",
    "    # print the last iterations \n",
    "    print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / ((i % log_interval) + 1), 100.*correct/total))\n",
    "    writer.add_scalar(\"Training Cross Entropy Loss\", running_loss / ((i % log_interval) + 1), i + 1)\n",
    "    writer.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "\n",
    "print('Training Done')\n",
    "writer_pp.add_graph(cnn_net_pp, inputs)\n",
    "writer_pp.flush()\n",
    "writer_pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qVuqAEdVtPk"
   },
   "source": [
    "# 5.2 DeepSpeed 분산 학습\n",
    "\n",
    "DeepSpeed 라이브러리는 단일 GPU에서 로우앤드 클러스터, 거대한 슈퍼컴퓨터에 이르는 다양한 하드웨어 크기에 대한 분산 학습을 위한 딥 러닝 최적화 라이브러리입니다.\n",
    "\n",
    "<img src=\"https://www.deepspeed.ai/assets/images/3d-parallelism.png\" width=\"650\" />\n",
    "\n",
    "\n",
    "- 단일 GPU/멀티 GPU/멀티 노드에 대한 혼합 정밀도의 분산 학습\n",
    "- 파이프라인 병렬화 및 메가트론-LM 텐서 병렬화와의 통합 \n",
    "- ZeRO(Zero Redundancy Optimizer) 메모리 최적화 기술\n",
    "- Zero-Offload 데이터 및 연산 CPU 오프로드\n",
    "- Mixture of Experts(MoE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-0x6ODbVtPk"
   },
   "source": [
    "## 5.2.1 DeepSpeed로 코드 실행하기\n",
    "\n",
    "DeepSpeed 엔진은 `torch.nn.module`로 정의된 신경망을 감쌀 수 있습니다. DeepSpeed를 사용하여 이전 모델을 작성하려면 다음과 같은 작업이 필요합니다.\n",
    "\n",
    "- DeepSpeed Model 엔진과 옵티마이저를 인스턴스화 합니다. : DeepSpeed 이니셜라이저를 다음과 같이 사용합니다. \n",
    "`model_engine, optimizer= deepspeed.initialize(args=args, model=Your_Network, model_parameters=parameters, training_data=trainset)`\n",
    "- 변수`args` 는 훈련 인자와 DeepSpeed 인자를 포함해야 합니다. `deepspeed.add_config_arguments(parser)`를 사용하여 DeepSpeed 인수를 파서에 추가할 수 있습니다.\n",
    "- 코드의 나머지 부분에 있는 `Your_Network` 대신 deepspeed `model_engine`을 참조하십시오.\n",
    "`torch.distributed.init_process_group(...)`를 활용한 분산 학습 구현을 `deepspeed.init_distributed()`로 대체합니다.\n",
    "\n",
    "[전용 DeepSpeed 설명서](https://www.deepspeed.ai/getting-started/#writing-deepspeed-models) 를 사용하여 DeepSpeed 모델을 작성하는 방법에 대해 자세히 알아보십시오.\n",
    "\n",
    "DeepSpeed 인수들은 JSON 구성 파일 전체에 전달할 수 있습니다. DeepSpeed 구성 파일을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUfMKbVGVtPl"
   },
   "outputs": [],
   "source": [
    "# Have a look at the DeepSpeed config\n",
    "! cat code/moe/ds_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUjf502SVtPl"
   },
   "outputs": [],
   "source": [
    "# import the relevant library\n",
    "import deepspeed\n",
    "\n",
    "# define the argument classe embedding our training arguments and DeepSpeed\n",
    "class Args:\n",
    "    log_interval=100 \n",
    "    batch_size=64\n",
    "    epochs=2\n",
    "    deepspeed = True\n",
    "    deepspeed_config = \"code/moe/ds_config.json\"\n",
    "    local_rank= 0\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kgs3nocVtPm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the CNN network\n",
    "cnn_net_ds = CNN_Net()\n",
    "\n",
    "# Define the hyperparameters\n",
    "parameters = filter(lambda p: p.requires_grad, cnn_net_ds.parameters())\n",
    "\n",
    "# Wrap the CNN network with DeepSpeed\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(args=args, model=cnn_net_ds, model_parameters=parameters, training_data=trainset)\n",
    "\n",
    "# enable mixed precision\n",
    "fp16 = model_engine.fp16_enabled()\n",
    "\n",
    "device = model_engine.local_rank\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Tensorboard event recording directory \n",
    "writer_ds = SummaryWriter('megatron/tensorboard/cifar10_DS')                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xF4GQhLLVtPm"
   },
   "outputs": [],
   "source": [
    "# Train the CNN with DeepSpeed\n",
    "for epoch in range(epochs): \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        if fp16:\n",
    "            inputs = inputs.half()        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_engine(inputs)             # Changed net_cnn to model_engine\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        model_engine.backward(loss)                # Changed net_cnn to model_engine\n",
    "        model_engine.step()                        # Changed net_cnn to model_engine\n",
    "        \n",
    "        # print the loss and accuracy metrics very log_interval mini-batches\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        if i % log_interval == (log_interval - 1):  \n",
    "            print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / log_interval, 100.*correct/total))\n",
    "            writer_ds.add_scalar(\"Training Cross Entropy Loss\", running_loss / log_interval, i + 1)\n",
    "            writer_ds.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # print the last iterations \n",
    "    print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / ((i % log_interval) + 1), 100.*correct/total))\n",
    "    writer.add_scalar(\"Training Cross Entropy Loss\", running_loss / ((i % log_interval) + 1), i + 1)\n",
    "    writer.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "    \n",
    "print('Training Done')\n",
    "writer_ds.add_graph(model_engine, inputs)\n",
    "writer_ds.flush()\n",
    "writer_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_K-aJRRVtPm"
   },
   "source": [
    "이전 단계들은 python 스크립트 [cifar10_deepspeed.py](./code/moe/cifar10_deepspeed.py) 로 집계됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS5Q_uO4VtPm"
   },
   "source": [
    "## 5.2.2 데이터 병렬화를 활용한 스케일 아웃 트레이닝\n",
    "\n",
    "이제 분산 학습 기법을 사용하여 이전에 진행한 트레이닝을 확장해 보겠습니다. 데이터 병렬화 분산을 활용하여 4개의 GPU에서 이전 코드를 실행하려면 torch.distributed.launch 명령어를 사용하는 대신 deepspeed를 도입하면 됩니다.\n",
    "\n",
    "`python -m torch.distributed.launch --nproc_per_node=4 my_code.py <args>`\n",
    "\n",
    "DeepSpeed를 사용하려면 단순히 torch.distributed.launch를 deepspeed로 바꾸고 새 인수(--deepspeed ds_config.json)를 추가하면 됩니다.\n",
    "\n",
    "`deepspeed --num_gpus=4 my_code.py  <args> --deepspeed ds_config.json`\n",
    "\n",
    "다음 셀을 실행하여 DeepSpeed가 포함된 4개의 GPU에서 이전 cifar10_deepspeed.py 트레이닝 코드를 실행합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsOMVm8RVtPn"
   },
   "outputs": [],
   "source": [
    "# Kill zombie processes\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yb4u720dVtPn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run the training on 4 GPUs with Data parallel\n",
    "! deepspeed --num_gpus=4 /dli/code/moe/cifar10_deepspeed.py \\\n",
    "    --deepspeed \\\n",
    "    --deepspeed_config /dli/code/moe/ds_config.json \\\n",
    "    --profile-execution=True \\\n",
    "    --profile-name='zero0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr6Xb2Z2VtPn"
   },
   "source": [
    "SLURM 기반 클러스터에서 동일하게 실행하려면 원하는 리소스를 할당하는 SBATCH 스크립트를 작성하고 동일한 DeepSpeed 명령어를 호출하기만 하면 됩니다. \n",
    "\n",
    "다음 셀을 실행하여 DeepSpeed로 이전 트레이닝을 실행할 노드 2개를 할당하는 SBATCH 스크립트를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHM3_9PYVtPn"
   },
   "outputs": [],
   "source": [
    "%%writefile /dli/code/run_cifar10_deepspeed_2Nodes.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=dli_ds\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=1       \n",
    "#SBATCH --cpus-per-task=32 ### Number of threads per task (OMP threads)\n",
    "#SBATCH -o /dli/megatron/logs/%j.out\n",
    "#SBATCH -e /dli/megatron/logs/%j.err\n",
    "\n",
    "# Number of nodes\n",
    "NUM_NODES=2\n",
    "# Number of GPUs per node\n",
    "NUM_GPUS=2\n",
    "\n",
    "\n",
    "deepspeed --num_nodes=${NUM_NODES} --hostfile /dli/code/moe/hostfile --num_gpus=${NUM_GPUS} /dli/code/moe/cifar10_deepspeed.py \\\n",
    "    --deepspeed \\\n",
    "    --deepspeed_config /dli/code/moe/ds_config.json \\\n",
    "    --profile-execution=True \\\n",
    "    --profile-name='zero0_sbatch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nw9_9DJhVtPn"
   },
   "source": [
    "이제 이전 sbatch 스크립트 [run_cifar10_deepspeed_2Nodes.sh](./code/run_cifar10_deepspeed_2Nodes.sh) 를 제출하고 `squeue` 명령어를 사용하여 SLURM 대기열을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdVHVEN0VtPo"
   },
   "outputs": [],
   "source": [
    "# Submit the 2 nodes jobs\n",
    "! sbatch /dli/code/run_cifar10_deepspeed_2Nodes.sh\n",
    "\n",
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrKArh2OVtPo"
   },
   "outputs": [],
   "source": [
    "# Check GPU utilization on the master node\n",
    "! sleep 10\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XN5YxMe6VtPo"
   },
   "source": [
    "## 5.2.3 ZeRO : Zero Redundancy Optimizer \n",
    "\n",
    "[ZeRO](https://www.deepspeed.ai/tutorials/zero/)는 모델의 트레이닝 상태(가중치, 그레이디언트 및 옵티마이져 상태값)를 사용 가능한 장치에 분산시켜 각 GPU의 메모리 소비를 줄입니다. ZeRO는 3가지 누적 단계로 구현됩니다.\n",
    "\n",
    "-  **ZeRO-1:** 옵티마이저 상태는 프로세스 간에 분할되므로 각 프로세스는 파티션만 업데이트합니다. 예를 들어 Adam optimizer는 32비트 가중치와 첫 번째, 두 번째 모멘트 추정치를 저장합니다.\n",
    "-  **ZeRO-2:** Zero 1 외에도 모델 가중치를 업데이트하기 위한 축소된 32비트 그레이디언트도 분할되어 각 프로세스는 옵티마이저 상태의 해당 부분에 해당하는 그레이디언트만 유지합니다.\n",
    "- **ZeRO-3:** Zero 2 외에도 16비트 모델 매개 변수는 프로세스 전반에 걸쳐 분할됩니다. ZeRO-3는 포워드 및 백워드 패스 중에 자동으로 16비트 매개변수들을 수집 및 분할합니다. ZeRO-3에는 메모리 절감을 위해 CPU와 NVMe 메모리로 오프로드하는 [ZeRO-Infinity](https://arxiv.org/pdf/2104.07857.pdf) 엔진도 포함되어 있습니다.\n",
    "\n",
    "```\n",
    "{\n",
    " \"zero_optimization\": {\n",
    "    \"stage\": [0|1|2|3],\n",
    "    \"allgather_partitions\": [true|false],\n",
    "    \"allgather_bucket_size\": 5e8,\n",
    "    \"overlap_comm\": false,\n",
    "    \"reduce_scatter\": [true|false],\n",
    "    \"reduce_bucket_size\": 5e8,\n",
    "    \"contiguous_gradients\" : [true|false],\n",
    "    \"offload_param\": {\n",
    "      ...\n",
    "    },\n",
    "    \"offload_optimizer\": {\n",
    "      ...\n",
    "    },\n",
    "    \"stage3_max_live_parameters\" : 1e9,\n",
    "    \"stage3_max_reuse_distance\" : 1e9,\n",
    "    \"stage3_prefetch_bucket_size\" : 5e8,\n",
    "    \"stage3_param_persistence_threshold\" : 1e6,\n",
    "    \"sub_group_size\" : 1e12,\n",
    "    \"elastic_checkpoint\" : [true|false],\n",
    "    \"stage3_gather_16bit_weights_on_model_save\": [true|false],\n",
    "    \"ignore_unused_parameters\": [true|false]\n",
    "    \"round_robin_gradients\": [true|false]\n",
    "    }\n",
    "    }\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3H4vS34VtPo"
   },
   "source": [
    "<video controls src=\"https://www.microsoft.com/en-us/research/uploads/prod/2020/02/Turing-Animation.mp4?_=1\" width=\"560\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uQGNthdVtPo"
   },
   "source": [
    "메모리 절약을 위한 ZeRO 옵티마이저의 장점을 설명하기 위해 CNN 모델을 더 큰 신경망으로 확장해 보겠습니다. 우리는 작은 CNN 네트워크를 [large_model_deepspeed.py](./code/moe/large_model_deepspeed.py) 에서 1,100만 개의 매개 변수를 가진 Resnet152 모델로 교체했습니다.\n",
    "\n",
    "다음 그림은  *resnet152* 학습 단계에 대하여 [htop](https://htop.dev/) 명령어를 사용하여 CPU 사용량과 Pytorch Profiler (텐서보드에서 사용 가능)를 사용하여 프로파일링된 GPU 0 메모리를 보여줍니다. 우리는 no ZeRO와 ZeRO stage 3 + 오프로드 시 비교를 볼 수 있습니다. ZeRO 를 사용하지 않고 GPU 당 필요한 메모리 피크 값은 약 1.5 GB 입니다. ZeRO-3를 사용하여 매개 변수를 CPU로 오프로드하면 845MB만 사용합니다. 반면에 각 스텝 당 시간은 500ms에서 7000ms로 크게 증가했습니다!\n",
    "\n",
    "ZeRO infinity는 GPU의 수가 제한되어 있을 때 더 큰 모델로 확장할 수 있지만, 이는 데이터 이동에 상응하는 추가 학습 시간이 수반됩니다.\n",
    "<img src=\"images/zero_memory.png\" width=\"1250\" />\n",
    "\n",
    "\n",
    "Zero stage 3 옵티마이저를 실행하고 매개 변수의 CPU 오프로드를 사용하도록 설정합니다. 우리는 구성 파일을 준비해 두었고 GPU당 트레이닝 배치 크기를 512로 늘렸습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPUJbRckVtPo"
   },
   "outputs": [],
   "source": [
    "# Show DeepSpeed config file for Zero stage 3 Offload\n",
    "! cat /dli/code/moe/ds_config_stage_3.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QW7gYp0OVtPo"
   },
   "source": [
    "다음 셀을 실행하여 CIFAR-10 데이터 세트에 대해 *resnet152* 모델 학습을 실행합니다. 이 실험에서는 정확도가 아니라 메모리 소비에 관심이 있기 때문에 모델을 더 이상 평가하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niH6C6UJVtPp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! deepspeed --num_gpus=4 /dli/code/moe/large_model_deepspeed.py \\\n",
    "    --deepspeed \\\n",
    "    --deepspeed_config /dli/code/moe/ds_config_stage_3.json \\\n",
    "    --profile-execution=True \\\n",
    "    --profile-name='zero_resnet512_stage3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG35SAIpVtPp"
   },
   "source": [
    "다음 셀을 실행하여 브라우저에서 텐서보드에 대한 링크를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b__5JcjgVtPp"
   },
   "outputs": [],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/tensorboard/';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Tensorboard!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMQHt6K7VtPp"
   },
   "source": [
    "### 실험 : ZeRO Stage 1\n",
    "\n",
    "ZeRO Stage 1 실행 시간과 GPU/CPU 메모리 크기를 no ZeRO 및 ZeRO Stage 3 + 오프로드와 비교합니다. 우리는 이미 DeepSpeed 구성 파일을 준비해 두었습니다. 한 번 결과를 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4Qg9YFOVtPp"
   },
   "outputs": [],
   "source": [
    "# Show DeepSpeed config file for Zero stage 1 \n",
    "! cat /dli/code/moe/ds_config_stage_1.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOQ6gA-eVtPp"
   },
   "source": [
    "Execute the next cell to run the *resnet152* model training on the CIFAR-10 dataset with ZeRO Stage1. Replace the `FIXME` with the corresponding arguments. If you get stuck, you can look at the [solution](solutions/ex5.2.4.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocd1ri-nVtPp"
   },
   "outputs": [],
   "source": [
    "! deepspeed --num_gpus=4 /dli/code/moe/large_model_deepspeed.py \\\n",
    "    --deepspeed \\\n",
    "    --deepspeed_config #FIXEME \\\n",
    "    --profile-execution=True \\\n",
    "    --profile-name=#FIXEME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbI_FKnUVtPq"
   },
   "source": [
    "Compared to the run without ZeRO, Stage 1 allows to reduce the GPU memory usage from about 1.5GB to 1GB as it partitions the optimizer states across 4 GPUs meaning that each GPU is responsible for keeping in memory a part of the optimizer states and communicate them when necessary to others. In this case, no significant extra time is observed to run the step with ZeRO Stage 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5qh9IGjVtPq"
   },
   "source": [
    "## 선택사항: 5.2.4 오토 튜닝\n",
    "\n",
    "학습 실험을 설계할 때 하드웨어를 완전히 활용하고 높은 처리량을 달성하는 최적의 구성(마이크로 배치 크기 등)이 무엇인지 알기 어렵습니다. 일반적으로 하드웨어 구성 탐색은 수동으로 수행됩니다. 이러한 조정 프로세스는 번거롭고 시간이 많이 소요되며 구성은 하드웨어에 따라 다릅니다. DeepSpeed Autotuner는 학습 속도에 최적화된 DeepSpeed 구성 매개변수를 자동으로 검색합니다.\n",
    "오토 튜닝을 시작하려면 학습 스크립트에  `--autotuning run`  명령을 추가하고 구성 파일에서 다음과 같이 사용하도록 설정하십시오. \n",
    "\n",
    "```\n",
    "{\n",
    "  \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "\n",
    "  \"autotuning\": {\n",
    "    \"enabled\": true,\n",
    "    \"arg_mappings\": {\n",
    "      \"train_micro_batch_size_per_gpu\": \"--batch_size\"    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "DeepSpeed 구성 파일의 arg_mappings 사전(dictionary) 자동 조정 섹션은 DeepSpeed 구성의 매개 변수와 학습 스크립트 인자 간의 이름 매핑을 제공합니다. 또한  \"auto\" 를 평가할 수 있는 값의 벡터로 대체하여 검색 공간을 값 목록으로 제한할 수도 있습니다. \n",
    "\n",
    "오토 튜닝 기능에 대한 자세한 내용은 [DeepSpeed documentation](https://www.deepspeed.ai/tutorials/autotuning/)를 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-lOFm0nVtPq"
   },
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">축하합니다!</h2>\n",
    "\n",
    "다음으로 넘어가기 전에 대기열에서 실행 중이거나 대기 중인 작업이 없는지 확인해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxy3DDigVtPq"
   },
   "outputs": [],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAgoFPKgVtPq"
   },
   "source": [
    "아직 실행 중이거나 보류 중인 작업이 있는 경우 다음 셀을 실행하고 `scancel` 명령을 사용하여 모든 어드민 사용자의 작업을 취소합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvaBRn0DVtPq"
   },
   "outputs": [],
   "source": [
    "# Cancel admin user jobs\n",
    "! scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "! squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdfnGxVSVtPq"
   },
   "source": [
    "다음으로는 MoE(Mixture of Expert) 구성을 살펴보겠습니다. [06_MOE_alternative_models.ipynb](06_MOE_alternative_models.ipynb) 로 이동합니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "VMQgS4IjVtPh",
    "zMQHt6K7VtPp"
   ],
   "name": "05_Multi-Nodes_Distributed_Training_for_Computer_Vision.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
